import chromadb
from sentence_transformers import SentenceTransformer
from langchain_community.llms import GPT4All 


embedding_model = SentenceTransformer("all-MiniLM-L6-v2")


chroma_client = chromadb.PersistentClient(path="./znu_db")
collection = chroma_client.get_collection(name="znu_knowledge")


llm = GPT4All(model="./models/gpt4all-falcon.Q3_K_S.gguf")

  

def chat_rag(query):

    query_vector = embedding_model.encode(query).tolist()

    
    results = collection.query(
        query_embeddings=[query_vector],
        n_results=5 
    )

    # ØªØ±Ú©ÛŒØ¨ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒâ€ŒØ´Ø¯Ù‡
    context = " ".join(results["documents"][0])

    # Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ù…Ø¯Ù„ GPT4All Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®
    prompt = f"""
Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ± Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª Ù…Ø·Ø§Ù„Ø¹Ù‡ Ú©Ù† Ùˆ ÙÙ‚Ø· Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ù†â€ŒÙ‡Ø§ Ø¨Ù‡ Ø³ÙˆØ§Ù„ Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡. Ø§Ú¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ú¯Ùˆ Ú©Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ù†Ø¯Ø§Ø±Ù….
Ø§Ø·Ù„Ø§Ø¹Ø§Øª:
{context}

Ø³ÙˆØ§Ù„: {query}
Ø¬ÙˆØ§Ø¨:
"""

    response = llm.invoke(prompt)  # âœ… Ø±ÙˆØ´ Ø¬Ø¯ÛŒØ¯


    return response

# # Ø§Ø¬Ø±Ø§ÛŒ Ú†Øªâ€ŒØ¨Ø§Øª Ø¯Ø± ÛŒÚ© Ø­Ù„Ù‚Ù‡ (Ù¾Ø±Ø³Ø´ Ùˆ Ù¾Ø§Ø³Ø®)
# print("ğŸ¤– Ú†Øªâ€ŒØ¨Ø§Øª RAG Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª. Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ØŒ 'exit' Ø±Ø§ ØªØ§ÛŒÙ¾ Ú©Ù†ÛŒØ¯.")
# while True:
#     user_input = input(":Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯: ")
#     if user_input.lower() == "exit":
#         print("ğŸ‘‹ Ø®Ø±ÙˆØ¬ Ø§Ø² Ú†Øªâ€ŒØ¨Ø§Øª...")
#         break
#     answer = chat_rag(user_input)
#     print(f"ğŸ¤– Ù¾Ø§Ø³Ø®: {answer}")
